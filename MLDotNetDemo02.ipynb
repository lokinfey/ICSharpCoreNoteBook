{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Microsoft.ML Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#r \"nuget:Microsoft.ML , 1.3.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using System;\n",
    "using System.IO;\n",
    "using Microsoft.ML;\n",
    "using Microsoft.ML.Data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "public class SentimentIssue\n",
    "{\n",
    "  [LoadColumn(0)]\n",
    "  public string Text { get; set; }\n",
    "  [LoadColumn(1)]\n",
    "  public bool Label { get; set; }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "public class SentimentPrediction\n",
    "{\n",
    "   [ColumnName(\"PredictedLabel\")]\n",
    "   public bool Prediction { get; set; }\n",
    "   \n",
    "   public float Probability { get; set; }\n",
    "\n",
    "   public float Score { get; set; }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create MLContext to be shared across the model creation workflow objects "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "var mlContext = new MLContext(seed: 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 1: Common data loading configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "IDataView trainingData = mlContext.Data.LoadFromTextFile<SentimentIssue>(@\"dataset/mldataset/train_data.tsv\", hasHeader: true);\n",
    "IDataView testData = mlContext.Data.LoadFromTextFile<SentimentIssue>(@\"dataset/mldataset/train_data.tsv\", hasHeader: true);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 2: Common data process configuration with pipeline data transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "var dataProcessPipeline = mlContext.Transforms.Text.FeaturizeText(\"Features\", nameof(SentimentIssue.Text));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 3: Set the training algorithm, then create and config the modelBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "var trainer = mlContext.BinaryClassification.Trainers.LbfgsLogisticRegression(\"Label\", \"Features\");\n",
    "var trainingPipeline = dataProcessPipeline.Append(trainer);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 4: Train the model fitting to the DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ITransformer trainedModel = trainingPipeline.Fit(trainingData);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 5: Evaluate the model and show accuracy stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "var predictions = trainedModel.Transform(testData);\n",
    "var metrics = mlContext.BinaryClassification.Evaluate(data: predictions, labelColumnName: \"Label\", scoreColumnName: \"Score\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "*       Accuracy: 71.20 %"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "*       Area Under Curve:      79.77 %"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "*       Area under Precision recall Curve:  78.96 %"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "*       F1Score:  71.20 %"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "*       LogLoss:  .87"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "*       LogLossReduction:  .13"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "*       PositivePrecision:  .71"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "*       PositiveRecall:  .71"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "*       NegativePrecision:  .71"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "*       NegativeRecall:  71.20 %"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Console.WriteLine($\"*       Accuracy: {metrics.Accuracy:P2}\");\n",
    "Console.WriteLine($\"*       Area Under Curve:      {metrics.AreaUnderRocCurve:P2}\");\n",
    "Console.WriteLine($\"*       Area under Precision recall Curve:  {metrics.AreaUnderPrecisionRecallCurve:P2}\");\n",
    "Console.WriteLine($\"*       F1Score:  {metrics.F1Score:P2}\");\n",
    "Console.WriteLine($\"*       LogLoss:  {metrics.LogLoss:#.##}\");\n",
    "Console.WriteLine($\"*       LogLossReduction:  {metrics.LogLossReduction:#.##}\");\n",
    "Console.WriteLine($\"*       PositivePrecision:  {metrics.PositivePrecision:#.##}\");\n",
    "Console.WriteLine($\"*       PositiveRecall:  {metrics.PositiveRecall:#.##}\");\n",
    "Console.WriteLine($\"*       NegativePrecision:  {metrics.NegativePrecision:#.##}\");\n",
    "Console.WriteLine($\"*       NegativeRecall:  {metrics.NegativeRecall:P2}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 6: Save/persist the trained model to a .ZIP file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlContext.Model.Save(trainedModel, trainingData.Schema, @\"dataset/mldataset/SentimentModel.zip\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRY IT: Make a single test prediction loding the model from .ZIP file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SentimentIssue sampleStatement = new SentimentIssue { Text = \"This is a very good film\" };"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "var predEngine = mlContext.Model.CreatePredictionEngine<SentimentIssue, SentimentPrediction>(trainedModel);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "var resultprediction = predEngine.Predict(sampleStatement);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=============== Single Prediction  ==============="
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text: This is a very good film | Prediction: Toxic sentiment | Probability of being toxic: 0.6830624 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Console.WriteLine($\"=============== Single Prediction  ===============\");\n",
    "Console.WriteLine($\"Text: {sampleStatement.Text} | Prediction: {(Convert.ToBoolean(resultprediction.Prediction) ? \"Toxic\" : \"Non Toxic\")} sentiment | Probability of being toxic: {resultprediction.Probability} \");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "C#",
   "language": "csharp",
   "name": "csharpcore"
  },
  "language_info": {
   "file_extension": ".cs",
   "mimetype": "text/x-csharp",
   "name": ".netstandard",
   "pygments_lexer": "CSharp",
   "version": "4.0.30319"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
